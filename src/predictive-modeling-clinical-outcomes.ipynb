{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b634e-a702-48d2-ad8e-84dc23ae0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vitals   = pd.read_csv(\"../data/vitals.csv\")\n",
    "events   = pd.read_csv(\"../data/events.csv\")\n",
    "patients = pd.read_csv(\"../data/patients.csv\")\n",
    "\n",
    "def plot_patient_timeline(pid, span_hours=12, start_minute=0):\n",
    "    df = vitals[vitals.patient_id==pid].copy()\n",
    "    if df.empty:\n",
    "        print(\"No such patient.\")\n",
    "        return\n",
    "    df = df.sort_values(\"minute\").reset_index(drop=True)\n",
    "\n",
    "    # Slice a window\n",
    "    end_minute = start_minute + span_hours*60\n",
    "    dfw = df[(df.minute>=start_minute) & (df.minute<end_minute)].copy()\n",
    "\n",
    "    ev = events[events.patient_id==pid]\n",
    "    hypo_mins = set(ev[ev.event==\"hypotension_start\"][\"minute\"].tolist())\n",
    "\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(12, 9), sharex=True)\n",
    "    chs = [\"HR\", \"MAP\", \"SpO2\", \"RR\", \"Temp\"]\n",
    "    for ax, ch in zip(axes, chs):\n",
    "        ax.plot(dfw[\"minute\"], dfw[ch], lw=1.2)\n",
    "        ax.set_ylabel(ch)\n",
    "        # mark hypotension starts\n",
    "        for m in sorted(hypo_mins):\n",
    "            if start_minute <= m < end_minute:\n",
    "                ax.axvline(m, ls=\"--\", alpha=0.3)\n",
    "    axes[-1].set_xlabel(\"minute\")\n",
    "    fig.suptitle(f\"Patient {pid} timeline ({span_hours}h from minute {start_minute})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: visualize the first patient found\n",
    "example_pid = int(vitals.patient_id.iloc[0])\n",
    "plot_patient_timeline(example_pid, span_hours=12, start_minute=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138db2b-526a-4da2-8292-13fd2c82a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX = 120     # minutes of context\n",
    "HORIZ = 60    # minutes to look ahead for event\n",
    "STEP = 10     # stride between windows\n",
    "\n",
    "SIGNALS = [\"HR\", \"MAP\", \"SpO2\", \"RR\", \"Temp\"]\n",
    "\n",
    "# Build a fast lookup for hypotension start minutes per patient\n",
    "hypo_dict = (events[events.event==\"hypotension_start\"]\n",
    "             .groupby(\"patient_id\")[\"minute\"].apply(set)\n",
    "             .to_dict())\n",
    "\n",
    "def make_windows_for_patient(df_pid, ctx=CTX, horiz=HORIZ, step=STEP):\n",
    "    \"\"\"Return list of dicts with X (DataFrame window), y (0/1), metadata.\"\"\"\n",
    "    rows = []\n",
    "    minutes = df_pid[\"minute\"].values\n",
    "    last_start = minutes.max() - (ctx + horiz)  # ensure we have enough future\n",
    "    hypo_minutes = hypo_dict.get(int(df_pid.patient_id.iloc[0]), set())\n",
    "\n",
    "    for t0 in range(0, int(last_start)+1, step):\n",
    "        t1 = t0 + ctx\n",
    "        t_future0, t_future1 = t1, t1 + horiz\n",
    "\n",
    "        win = df_pid[(df_pid.minute>=t0) & (df_pid.minute<t1)]\n",
    "        if len(win) < ctx * 0.9:  # too many gaps\n",
    "            continue\n",
    "\n",
    "        # label = 1 if any hypotension start in [t1, t1+horiz)\n",
    "        y = int(any((m >= t_future0) and (m < t_future1) for m in hypo_minutes))\n",
    "\n",
    "        rows.append({\n",
    "            \"patient_id\": int(df_pid.patient_id.iloc[0]),\n",
    "            \"t0\": t0,\n",
    "            \"t1\": t1,\n",
    "            \"X\": win[SIGNALS + [s+\"_obs\" for s in SIGNALS]].copy(),  # include obs masks\n",
    "            \"y\": y\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# Build windows for all patients (this can take a bit—okay for ~60 patients)\n",
    "windows = []\n",
    "for pid, dfp in vitals.groupby(\"patient_id\"):\n",
    "    dfp = dfp.sort_values(\"minute\").reset_index(drop=True)\n",
    "    windows.extend(make_windows_for_patient(dfp))\n",
    "\n",
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2d894-7221-4a09-939c-d1c91fd9347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_window_features(Xdf):\n",
    "    # Xdf has columns: HR, MAP, SpO2, RR, Temp, and *_obs\n",
    "    feats = {}\n",
    "    for ch in SIGNALS:\n",
    "        x = Xdf[ch].values.astype(float)\n",
    "        obs = Xdf.get(ch+\"_obs\", pd.Series(np.ones_like(x))).values.astype(float)\n",
    "        # basic stats\n",
    "        feats[f\"{ch}_mean\"] = np.nanmean(x)\n",
    "        feats[f\"{ch}_std\"]  = np.nanstd(x)\n",
    "        feats[f\"{ch}_min\"]  = np.nanmin(x)\n",
    "        feats[f\"{ch}_max\"]  = np.nanmax(x)\n",
    "        q25, q75 = np.nanpercentile(x, [25, 75])\n",
    "        feats[f\"{ch}_iqr\"]  = q75 - q25\n",
    "        feats[f\"{ch}_last\"] = x[-1]\n",
    "        # simple slope via linear fit on index\n",
    "        idx = np.arange(len(x))\n",
    "        # handle NaNs (mask)\n",
    "        mask = ~np.isnan(x)\n",
    "        if mask.sum() >= 5:\n",
    "            a = np.polyfit(idx[mask], x[mask], 1)[0]\n",
    "        else:\n",
    "            a = 0.0\n",
    "        feats[f\"{ch}_slope\"] = a\n",
    "        # recent change (last - median of first half)\n",
    "        mid = len(x)//2\n",
    "        feats[f\"{ch}_delta_mid\"] = x[-1] - np.nanmedian(x[:mid])\n",
    "        # missingness\n",
    "        feats[f\"{ch}_miss_rate\"] = 1.0 - np.nanmean(obs) if obs.size else np.nan\n",
    "    return feats\n",
    "\n",
    "# Vectorize to a DataFrame\n",
    "feat_rows, y_rows, pid_rows = [], [], []\n",
    "for w in windows:\n",
    "    feat_rows.append(summarize_window_features(w[\"X\"]))\n",
    "    y_rows.append(w[\"y\"])\n",
    "    pid_rows.append(w[\"patient_id\"])\n",
    "\n",
    "X = pd.DataFrame(feat_rows)\n",
    "y = np.array(y_rows).astype(int)\n",
    "groups = np.array(pid_rows)  # to split by patient\n",
    "\n",
    "X.shape, y.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800e6e5-6424-4c9f-968b-3b34184b70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "groups_train = groups[train_idx]; groups_val = groups[val_idx]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_val_sc   = scaler.transform(X_val)\n",
    "\n",
    "# handle imbalance (if any)\n",
    "pos_rate = y_train.mean()\n",
    "print(\"Train positives:\", y_train.sum(), \"of\", len(y_train), f\"({pos_rate:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808b22e-fb85-4da6-91a3-4d1214c20c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train_sc, y_train)\n",
    "\n",
    "p_val = clf.predict_proba(X_val_sc)[:,1]\n",
    "auroc  = roc_auc_score(y_val, p_val)\n",
    "auprc  = average_precision_score(y_val, p_val)\n",
    "\n",
    "print(f\"Validation AUROC: {auroc:.3f}  |  AUPRC: {auprc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6252f-abd5-4ae9-9f4b-8424b4b6a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, thr = precision_recall_curve(y_val, p_val)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(rec, prec, lw=2)\n",
    "plt.xlabel(\"Recall (Sensitivity)\")\n",
    "plt.ylabel(\"Precision (PPV)\")\n",
    "plt.title(\"Precision–Recall curve (validation)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# choose a threshold that gives ~0.3 alerts per hour per patient (demo heuristic)\n",
    "# here we just set a threshold by percentile:\n",
    "thr_choice = np.percentile(p_val, 100*(1-0.10))  # top 10% risk = alert\n",
    "y_hat = (p_val >= thr_choice).astype(int)\n",
    "cm = confusion_matrix(y_val, y_hat)\n",
    "cm, thr_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5aedeb-2a04-4415-b168-7ec9cdbeb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a map from patient -> earliest validation hypotension start\n",
    "val_pids = set(groups_val.tolist())\n",
    "pid_to_first_event = {}\n",
    "for pid in val_pids:\n",
    "    mins = sorted(list(hypo_dict.get(int(pid), set())))\n",
    "    pid_to_first_event[pid] = mins[0] if mins else None\n",
    "\n",
    "# Gather window meta for validation set\n",
    "val_meta = pd.DataFrame({\n",
    "    \"pid\": groups_val,\n",
    "    \"risk\": p_val,\n",
    "    \"y\": y_val\n",
    "})\n",
    "# We need the corresponding t1 (window end) for each validation window\n",
    "# Rebuild metadata list aligned to val_idx\n",
    "t1_all = np.array([w[\"t1\"] for w in windows])\n",
    "val_t1 = t1_all[val_idx]\n",
    "val_meta[\"t1\"] = val_t1\n",
    "\n",
    "# Choose threshold as above\n",
    "val_meta[\"alert\"] = (val_meta[\"risk\"] >= thr_choice).astype(int)\n",
    "\n",
    "lead_times = []\n",
    "for pid, dfp in val_meta.groupby(\"pid\"):\n",
    "    event_min = pid_to_first_event.get(pid)\n",
    "    if event_min is None:\n",
    "        continue\n",
    "    alerts_before_event = dfp[dfp[\"alert\"]==1].copy()\n",
    "    alerts_before_event = alerts_before_event[alerts_before_event[\"t1\"] <= event_min]\n",
    "    if len(alerts_before_event):\n",
    "        first_alert_t1 = alerts_before_event.sort_values(\"t1\").iloc[0][\"t1\"]\n",
    "        lead_times.append(event_min - first_alert_t1)\n",
    "\n",
    "if lead_times:\n",
    "    lt = np.array(lead_times)\n",
    "    print(f\"Lead-time (minutes): median={np.median(lt):.1f}, IQR=({np.percentile(lt,25):.1f}, {np.percentile(lt,75):.1f}), n={len(lt)}\")\n",
    "else:\n",
    "    print(\"No events or no alerts before events in validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93d506-d015-41f3-a135-a6a46601efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost feature importance (gain-based)\n",
    "imp = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "imp.head(15)\n",
    "plt.figure(figsize=(6,6))\n",
    "imp.head(20).iloc[::-1].plot(kind=\"barh\")\n",
    "plt.title(\"Top 20 feature importances (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bba2ef-6721-4e9e-8ac9-6f44dc474e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1) Replace inf with NaN (just in case)\n",
    "X_num = X.replace([np.inf, -np.inf], np.nan).copy()\n",
    "\n",
    "# 2) Drop columns that are entirely NaN (can happen if a feature couldn’t be computed anywhere)\n",
    "all_nan_cols = [c for c in X_num.columns if X_num[c].isna().all()]\n",
    "if all_nan_cols:\n",
    "    print(\"Dropping all-NaN columns:\", all_nan_cols)\n",
    "    X_num = X_num.drop(columns=all_nan_cols)\n",
    "\n",
    "# 3) Median-impute remaining NaNs (robust for skewed clinical features)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imp = pd.DataFrame(imputer.fit_transform(X_num), columns=X_num.columns, index=X_num.index)\n",
    "\n",
    "# 4) Scale and embed\n",
    "Z = StandardScaler().fit_transform(X_imp)\n",
    "reducer = umap.UMAP(n_neighbors=30, min_dist=0.1, random_state=42)\n",
    "emb = reducer.fit_transform(Z)\n",
    "\n",
    "# now continue with KMeans + plots\n",
    "k = 5\n",
    "km = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = km.fit_predict(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11c9da-3c0e-490c-8864-3566a7c5b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "for c in range(k):\n",
    "    idx = clusters==c\n",
    "    plt.scatter(emb[idx,0], emb[idx,1], s=6, alpha=0.6, label=f\"C{c} (n={idx.sum()})\")\n",
    "plt.legend()\n",
    "plt.title(\"UMAP embedding of windows (colored by cluster)\")\n",
    "plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Risk-colored view (continuous)\n",
    "plt.figure(figsize=(7,6))\n",
    "sc = plt.scatter(emb[:,0], emb[:,1], s=6, c=y, alpha=0.7, cmap=\"viridis\")\n",
    "plt.colorbar(sc, label=\"Label (event within horizon)\")\n",
    "plt.title(\"UMAP embedding colored by label (risk proxy)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8184d3a-5dea-49c0-9087-a301671665d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
